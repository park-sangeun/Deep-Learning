{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leechanhoe/deep-learning-project/blob/master/batch_Normalization_%EC%A0%81%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwX92Dgf3QZq"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAflhzsZ3TN1"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yMHoiDR3W1N"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Block (Conv-Conv-Pool-Dropout)\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional Block (Conv-Conv-Pool-Dropout)\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Classifying\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgb6I6rm3c8X"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y91gJ8MB3hpV"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     horizontal_flip=True,\n",
        "#     )\n",
        "# datagen.fit(train_images)\n",
        "\n",
        "# def lr_schedule(epoch):\n",
        "#     lrate = 0.001\n",
        "#     if epoch > 25:\n",
        "#         lrate = 0.0005\n",
        "#     if epoch > 50:\n",
        "#         lrate = 0.0003\n",
        "#     if epoch > 75:\n",
        "#         lrate = 0.0001\n",
        "#     return lrate\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('best_cnn_model.h5', save_best_only=True)\n",
        "# 5번의 연속적인 epoch 동안 개선이 없을 때 학습이 중단되도록 함\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9A3SDOUri8P"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# 변형된 이미지 추가 버전\n",
        "# history = model.fit(datagen.flow(train_images, train_labels, batch_size=128), epochs=30,  validation_split=0.1,\n",
        "#                     callbacks = [checkpoint, early_stopping, LearningRateScheduler(lr_schedule)])\n",
        "\n",
        "# 학습률 갈수록 작게 조정 버전\n",
        "# history = model.fit(train_images, train_labels, batch_size=128, epochs=100,  validation_split=0.1,\n",
        "#                     callbacks = [checkpoint, early_stopping, LearningRateScheduler(lr_schedule)])\n",
        "\n",
        "# 기본버전\n",
        "history = model.fit(train_images, train_labels, batch_size=128, epochs=100,  validation_split=0.1,\n",
        "                    callbacks = [checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKGWJdbb3kN_"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('CNN_CIFAR10.h5')\n",
        "model = load_model('CNN_CIFAR10.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2JsOHgO3lSW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['acc'], label='acc')\n",
        "plt.plot(history.history['val_acc'], label='val_acc')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# 손실 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(loc='best')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}